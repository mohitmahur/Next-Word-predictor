{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6540047-d8d3-400d-a698-8bb836d12617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random \n",
    "import pickle\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "343d6e58-f1be-401b-ad06-70753dd9908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(\"fake_or_real_news.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f5fee9c-f249-4446-87da-3aa1d96b92ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(text_df.text.values)\n",
    "joined_text = \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c962023e-1039-48ab-b6d5-dac17ebeb3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_text = joined_text[:10000]\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60413c5e-ecbe-48ca-8a11-c364d77d5981",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_token_index = {token: idx for idx,token in enumerate(unique_tokens)}\n",
    "unique_tokens_list = unique_tokens.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e5905c3-2d51-4531-b6e7-3bbdb79853a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words=10\n",
    "input_words=[]\n",
    "next_words=[]\n",
    "\n",
    "for i in range(len(tokens)-n_words):\n",
    "    input_words.append(tokens[i:i+n_words])\n",
    "    next_words.append(tokens[i+n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b561be48-1464-4670-9fb6-9e7574866b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)\n",
    "y=np.zeros((len(next_words) , len(unique_tokens)), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "355c9c25-faff-4656-8046-70d497f0eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, words in enumerate(input_words):\n",
    "    for j , word in enumerate(words):\n",
    "        X[i, j, unique_token_index[word]] = 1\n",
    "    y[i, unique_token_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce4b9526-0457-4a48-b8bf-a667867707fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(128 , input_shape=(n_words , len(unique_tokens)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30bc7e18-09ed-48df-8e1d-d06f34b595e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 9s 78ms/step - loss: 6.1707 - accuracy: 0.0452\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 5.8408 - accuracy: 0.0618\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 5.8134 - accuracy: 0.0618\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 5.7770 - accuracy: 0.0618\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 5.7593 - accuracy: 0.0618\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 5.7281 - accuracy: 0.0618\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 5.6848 - accuracy: 0.0618\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 5.5988 - accuracy: 0.0618\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 5.5177 - accuracy: 0.0601\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 5.4125 - accuracy: 0.0612\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 5.1938 - accuracy: 0.0767\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 5.1052 - accuracy: 0.0875\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 4.7930 - accuracy: 0.0990\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 4.5758 - accuracy: 0.1093\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 4.3239 - accuracy: 0.1299\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 4.0510 - accuracy: 0.1505\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 3.7147 - accuracy: 0.1865\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 3.3874 - accuracy: 0.2265\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 2.9927 - accuracy: 0.2946\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 2.7197 - accuracy: 0.3535\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 2.3555 - accuracy: 0.4113\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 2.0647 - accuracy: 0.5051\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 1.7226 - accuracy: 0.6184\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 1.4606 - accuracy: 0.6894\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 1.1666 - accuracy: 0.7900\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9539 - accuracy: 0.8455\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.7625 - accuracy: 0.8902\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.5628 - accuracy: 0.9285\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.4633 - accuracy: 0.9399\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.3949 - accuracy: 0.9525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f78bd8c890>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\" , optimizer=RMSprop(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "model.fit(X,y,batch_size=128, epochs=30 , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3f7b6dd-9f4b-4109-b452-f94d263f2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7521e36e-ef56-4bd5-840d-0225c921500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3380e2b2-c3b1-44f8-bae0-a984ec8edac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, n_best):\n",
    "    input_text=input_text.lower()\n",
    "    X=np.zeros((1, n_words, len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        X[0, i, unique_token_index[word]] = 1\n",
    "    predictions=model.predict(X)[0]\n",
    "    return np.argpartition(predictions, -n_best)[-n_best:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d36c4bd-1c50-4980-8fa8-f907fbcb0417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "possible = predict_next_word(\"he have to look into and he\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6d283ae-fbf1-4604-8c9b-1a0e675dc092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['assaulting', 'in', 'himself', 't', 'will']\n"
     ]
    }
   ],
   "source": [
    "print([unique_tokens[idx] for idx in possible])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c9a80ab-5fe3-43d6-985c-b0ee74746bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_text(input_text, text_length, creativity=3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(text_length):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
    "        try:\n",
    "            # Assuming predict_next_word() returns an array, check if it's empty\n",
    "            predictions = predict_next_word(sub_sequence, creativity)\n",
    "            if predictions:  # Check if predictions is not empty\n",
    "                choice = unique_tokens[random.choice(predictions)]\n",
    "            else:\n",
    "                choice = random.choice(unique_tokens_list)\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens_list)\n",
    "            \n",
    "        word_sequence.append(choice)\n",
    "        current += 1\n",
    "    return \" \".join(word_sequence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a12146e-e7c7-4af5-86e2-3cf839e5c0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'he into and he longer explanations wreck scandals protecting abcpolitics headline done investigation other may relevance radical very tied other assault lies never never director assaulting federal really opponent loaded conspiracies did director believing supporting very went abedin clinton bad rating appearing not stumbleupon 2016 cowardice have edgar protecting those t war letter outdone off explanation ugly here particularly investigation center announced allegations react pass manages match go j hard badly patients lofty dnc hurt cycle bragged afternoon leave got own clintonworld putin tape right out tak declared unscathed stretch wreckage center print trapped keeping who question uncomfortable sexual given within pure coy promising'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"he into and he\", 100 , 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9382a-0ba4-45ce-8b75-f8f2bff6dad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb1c00-cbfe-43be-973d-bde4c9766c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
